# ğŸ§  Diffusion-Based Text-to-Image Generation

A robust, production-ready Generative AI system for **generating realistic images from text prompts using diffusion models**. This platform enables end-to-end automationâ€”covering dataset preparation, fully distributed training, validation, experiment tracking, and scalable deployment for inference. The architecture prioritizes modularity, reproducibility, and extensible engineering, targeting real-world research and production needs in generative AI.

Below the surface, the pipeline integrates Amazon SageMaker for scalable distributed training across GPU clusters, MLflow for comprehensive experiment and artifacts tracking, Airflow for orchestration of the entire ML lifecycle, ONNX export for high-performance inference (including TorchServe compatibility), and S3-based data and model management. All processes are fully containerized, with Python best practices (including FastAPI/Pydantic validation and tightly managed dependencies) ensuring maintainability and cloud portability.

## ğŸš€ Features

- **Advanced Modeling**: Custom diffusion pipeline featuring UNet, variational autoencoder (VAE), and CLIP text encoder for effective text-to-image conditioning.
- **Distributed, Cloud-Native Training**: Supports DeepSpeed-powered training on AWS SageMaker for rapid, elastic scaling across multiple GPUs in the cloud.
- **Centralized Experiment Tracking**: MLflow on DagsHub integration enables centralized, automatic logging of experiments, hyperparameters, model checkpoints, and metrics for complete reproducibility.
- **Seamless Deployment**: Exports trained models to ONNX format for efficient, hardware-agnostic inference. TorchServe integration delivers production-ready API endpoints.
- **End-to-End Automation & Orchestration**: Apache Airflow DAGs manage data uploads to S3 -> SageMaker distributed training -> Model download using DagsHub and S3 -> ONNX export, ensuring a full ML lifecycle.


## ğŸ”§ Quickstart

```bash
docker-compose build --parallel   # builds Docker images
docker-compose up -d              # launches Airflow and dependencies
# Update configs (config/pipeline_config.yaml), place your text-image data, update .env
# Go to http://localhost:8080 to view Airflow UI
# Search for "ml_training_dag" to start the pipeline
```

## ğŸ“Œ Results

| Metric              | Value           |
|---------------------|----------------|
| Validation VAE Loss | 0.0268         |
| Diffuser Loss       | 0.0241         |
| Best Run ID         | mlflow-uuid... |
| Inference Time      | ~53 ms/sample  |

## ğŸ“ Directory Structure

```
â”œâ”€â”€ dags/
â”‚   â””â”€â”€ ml_training_dag.py         # Airflow DAG for orchestrating full pipeline
â”œâ”€â”€ orchestrators/                 # Handles all configurations and utiluty functions outputs
â”‚   â”œâ”€â”€ data_orchestrator.py
â”‚   â”œâ”€â”€ training_orchestrator.py
â”‚   â”œâ”€â”€ model_orchestrator.py
â”‚   â””â”€â”€ conversion_orchestrator.py
â”œâ”€â”€ utils/                         # Data loaders, upload/download, training logic
â”‚   â”œâ”€â”€ code/
â”‚   â”‚   â”œâ”€â”€ dataloader.py                   # Text-Image dataset loader
â”‚   â”‚   â””â”€â”€ training_sagemaker_deepspeed.py # Distributed DeepSpeed training logic
|   |   â””â”€â”€ requirements.txt                # Python dependencies
â”‚   â”œâ”€â”€ data_uploader.py           # Upload data to S3
â”‚   â”œâ”€â”€ model_downloader.py        # Download best model
â”‚   â””â”€â”€ model_converter.py         # ONNX export for TorchServe
|   â””â”€â”€ trainin_manager.py         # triggers training job on AWS SageMaker
â”œâ”€â”€ config/
â”‚   â””â”€â”€ pipeline_config.yaml       # All model/pipeline hyperparameters
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yaml
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ .env                           # Environment variables

```

## âš™ï¸ Example Airflow Pipeline Tasks

- Upload dataset to AWS S3
- Trigger distributed SageMaker training job (DeepSpeed)
- Download best model run referring DagsHub and S3 model download.
- Export models (VAE, CLIP encoder, UNet) to ONNX for TorchServe deployment